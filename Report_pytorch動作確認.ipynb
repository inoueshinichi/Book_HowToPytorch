{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### listの動作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "layers = [1,2,3]\n",
    "layers += [5,6,7]\n",
    "print(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.Tensorの次元の増減"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "weight = nn.Parameter(torch.Tensor(512))\n",
    "init.constant_(weight, 20)\n",
    "print(weight.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.unsqueeze(0).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.unsqueeze(0).unsqueeze(2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 1, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.unsqueeze(0).unsqueeze(2).unsqueeze(3).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 512, 38, 38])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 5\n",
    "x = torch.ones((batch_size, 512, 38, 38))\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 対象の変数の次元を別の変数の次元と同じにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 512, 38, 38])\n"
     ]
    }
   ],
   "source": [
    "ww = weight.unsqueeze(0).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
    "print(ww.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 512, 38, 38])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.pow(2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 38, 38])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.pow(2).sum(dim=1).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 次元を保ったままの和算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 38, 38])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.pow(2).sum(dim=1, keepdim=True).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 38, 38])\n",
      "tensor([[[22.6274, 22.6274, 22.6274,  ..., 22.6274, 22.6274, 22.6274],\n",
      "         [22.6274, 22.6274, 22.6274,  ..., 22.6274, 22.6274, 22.6274],\n",
      "         [22.6274, 22.6274, 22.6274,  ..., 22.6274, 22.6274, 22.6274],\n",
      "         ...,\n",
      "         [22.6274, 22.6274, 22.6274,  ..., 22.6274, 22.6274, 22.6274],\n",
      "         [22.6274, 22.6274, 22.6274,  ..., 22.6274, 22.6274, 22.6274],\n",
      "         [22.6274, 22.6274, 22.6274,  ..., 22.6274, 22.6274, 22.6274]]])\n"
     ]
    }
   ],
   "source": [
    "xx = x.pow(2).sum(dim=1, keepdim=True).sqrt()+1e-10\n",
    "print(xx.size())\n",
    "print(xx[0, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 512, 38, 38])\n",
      "tensor([[[[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]]],\n",
      "\n",
      "\n",
      "        [[[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]]],\n",
      "\n",
      "\n",
      "        [[[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]]],\n",
      "\n",
      "\n",
      "        [[[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]]],\n",
      "\n",
      "\n",
      "        [[[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "wx = xx * ww\n",
    "print(wx.size())\n",
    "print(wx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### list or np.ndarray からtorch.tensorを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., -1.],\n",
       "        [ 1., -1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1.0, -1.0], [1.0, -1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]], dtype=torch.int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "torch.tensor(np.array([[1,2,3],[4,5,6]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.tensor()はいつもデータをコピーする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ・タイプを指定してtensorを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0],\n",
       "        [0, 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros([2,4], dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.tensorのスライシング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(x[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 8, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "x[0][1] = 8\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.tensorからpython定義の数値を抽出する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1]])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1]])\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5000)\n",
      "2.5\n",
      "torch.strided\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(2.5)\n",
    "print(x)\n",
    "print(x.item())\n",
    "print(x.layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.tensorは自動微分OFFの状態で生成される"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requires_grad:  False\n",
      "torch.strided\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1., -1.], [1., 1.]])\n",
    "print(\"requires_grad: \", x.requires_grad)\n",
    "print(x.layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requires_grad:  True\n",
      "x.grad:  None\n",
      "out:  tensor(4., grad_fn=<SumBackward0>)\n",
      "x.grad after out.backward(): \n",
      " tensor([[ 2., -2.],\n",
      "        [ 2.,  2.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1., -1.], [1., 1.]], requires_grad=True)\n",
    "print(\"requires_grad: \", x.requires_grad)\n",
    "print(\"x.grad: \", x.grad)\n",
    "out = x.pow(2).sum()\n",
    "print(\"out: \", out)\n",
    "out.backward()\n",
    "print(\"x.grad after out.backward(): \\n\", x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在の実装では, torch.tensorはメモリのオーバヘッドが大きいので、小さな複数のtorch.tensorを運用するのはメモリ消費が激しくなる."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dtypeとdeviceを引き継きながら、既存データからデータをコピーしたtorch.tensorを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1],\n",
      "        [2, 3]], dtype=torch.int8)\n",
      "tensor([1, 1], dtype=torch.int8)\n",
      "tensor([1, 1], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones((2,), dtype=torch.int8)\n",
    "data = [[0,1],[2,3]]\n",
    "print(tensor.new_tensor(data))\n",
    "print(tensor.clone())\n",
    "print(tensor.clone().detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### requires_gradを変更する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[0,1],[2,3]], dtype=torch.float32)\n",
    "print(x.requires_grad)\n",
    "x.requires_grad_(True) # 浮動小数点型のみ勾配変数を持つ\n",
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new_full(size,fill_value,dtype=None,device=None,requires_grad=False) -> Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1.], dtype=torch.float64)\n",
      "cpu\n",
      "tensor([[3.1416, 3.1416, 3.1416, 3.1416],\n",
      "        [3.1416, 3.1416, 3.1416, 3.1416],\n",
      "        [3.1416, 3.1416, 3.1416, 3.1416]], dtype=torch.float64)\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# dtypeとdeviceを継承\n",
    "tensor = torch.ones((2,), dtype=torch.float64)\n",
    "print(tensor)\n",
    "print(tensor.device)\n",
    "new_tensor = tensor.new_full((3,4), fill_value=3.141592)\n",
    "print(new_tensor)\n",
    "print(new_tensor.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new_empty(size,dtype=None,device=None,requires_grad=False) -> Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.7444e-10, 1.6925e+22, 1.0991e-05],\n",
      "        [8.5828e-07, 1.3517e+22, 2.6977e-09]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(())\n",
    "tensor = tensor.new_empty((2,3))\n",
    "print(tensor)\n",
    "print(tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new_ones(size,dtype=None,device=None,requires_grad=False) -> Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1],\n",
       "        [1, 1, 1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor((), dtype=torch.int32)\n",
    "tensor.new_ones((2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new_zero(size,dtype=None,device=None,requires_grad=False) -> Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor((), dtype=torch.float64)\n",
    "tensor.new_zeros((2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.tensorがGPUメモリにあるか否かのチェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([])\n",
      "False\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor((), dtype=torch.float32)\n",
    "print(tensor)\n",
    "print(tensor.is_cuda)\n",
    "print(tensor.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quantizedか否かのチェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(tensor.is_quantized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorのdeviceチェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(tensor.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 次元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.dim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 転置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1],\n",
      "        [2, 3]], dtype=torch.int32)\n",
      "tensor([[0, 2],\n",
      "        [1, 3]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[0,1],[2,3]], dtype=torch.int32)\n",
    "print(x)\n",
    "print(x.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 要素数を維持しながらtensorの形状を変える。もし引数に与えた要素数が元の数値より低い場合は、元のtensorの中身は削られる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a shape torch.Size([3, 3])\n",
      "x shape torch.Size([9])\n",
      "resized a shape tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
      "c tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
      "False\n",
      "b shape torch.Size([2, 2])\n",
      "resized a shape tensor([[0, 1],\n",
      "        [2, 3]])\n",
      "a shape torch.Size([2, 2])\n",
      "y tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "resized y tensor([[0, 1],\n",
      "        [2, 3]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[0,1,2],[3,4,5],[6,7,8]])\n",
    "y = a.clone().detach()\n",
    "x = torch.tensor([0,1,2,3,4,5,6,7,8])\n",
    "print(\"a shape\", a.size())\n",
    "print(\"x shape\", x.size())\n",
    "print(\"resized a shape\", a.resize_as_(x))\n",
    "\n",
    "c = a.clone().detach() # 元tensor:aの自動微分の関係を引き継がないためにdetach()が必要。\n",
    "print(\"c\", c)\n",
    "print(c is a)\n",
    "\n",
    "b = torch.tensor([[9,8],[6,5]])\n",
    "print(\"b shape\", b.size())\n",
    "print(\"resized a shape\", a.resize_as_(b))\n",
    "print(\"a shape\", a.size())\n",
    "\n",
    "e = torch.tensor([[0,0],[0,0]])\n",
    "print(\"y\", y)\n",
    "print(\"resized y\", y.resize_as_(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 8732])\n",
      "tensor([[ 7,  2,  7,  ...,  4,  5, 15],\n",
      "        [ 1,  5,  1,  ...,  6, 11, 20],\n",
      "        [15,  6, 14,  ...,  0, 11,  2],\n",
      "        [ 1,  4,  1,  ..., 19,  5,  6],\n",
      "        [11,  6, 16,  ..., 14, 13, 16]])\n"
     ]
    }
   ],
   "source": [
    "num_batch = 5\n",
    "conf_t_label = torch.randint(0, 21,(num_batch, 8732))\n",
    "print(conf_t_label.size())\n",
    "print(conf_t_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True,  True,  True,  ...,  True,  True,  True],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True],\n",
      "        [ True,  True,  True,  ..., False,  True,  True],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True]])\n"
     ]
    }
   ],
   "source": [
    "pos_mask = conf_t_label > 0\n",
    "print(pos_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8318],\n",
      "        [8316],\n",
      "        [8305],\n",
      "        [8294],\n",
      "        [8311]])\n"
     ]
    }
   ],
   "source": [
    "num_pos = pos_mask.long().sum(dim=1, keepdim=True)\n",
    "print(num_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([43660])\n",
      "tensor([ 0.1042,  0.2166,  0.0200,  ...,  0.8004, -1.0643,  1.3610])\n"
     ]
    }
   ],
   "source": [
    "loss_c = torch.randn((num_batch * 8732,))\n",
    "print(loss_c.size())\n",
    "print(loss_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 8732])\n",
      "tensor([[ 0.1042,  0.2166,  0.0200,  ..., -0.4098, -0.7046, -0.3654],\n",
      "        [ 1.3358,  0.1795,  0.5782,  ...,  0.1677,  0.1480,  1.0245],\n",
      "        [-0.7093,  0.0204, -0.6827,  ...,  0.6882,  0.2496,  0.8670],\n",
      "        [-0.0508, -0.4019, -0.0333,  ..., -1.3569, -0.5838, -1.6940],\n",
      "        [ 1.0672, -0.0114, -0.4001,  ...,  0.8004, -1.0643,  1.3610]])\n"
     ]
    }
   ],
   "source": [
    "loss_c2 = loss_c.view(num_batch, -1)\n",
    "print(loss_c2.size())\n",
    "print(loss_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1042,  0.2166,  0.0200,  ...,  0.8004, -1.0643,  1.3610])\n",
      "torch.Size([41544])\n"
     ]
    }
   ],
   "source": [
    "print(loss_c2[pos_mask])\n",
    "print(loss_c2[pos_mask].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 8732])\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.6882, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "loss_c3 = loss_c2.clone()\n",
    "loss_c3[pos_mask] = 0\n",
    "print(loss_c3.size())\n",
    "print(loss_c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_loss_c3, mapping_loss_c3_index = loss_c3.sort(dim=1, descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.0382,  2.2594,  2.2516,  ..., -2.1319, -2.2270, -2.3968],\n",
      "        [ 2.7377,  2.5797,  2.5308,  ..., -2.4066, -2.4149, -3.0637],\n",
      "        [ 2.7430,  2.7130,  2.4176,  ..., -2.5612, -2.8135, -3.4760],\n",
      "        [ 2.9681,  2.6779,  2.6597,  ..., -2.6926, -2.7973, -3.0354],\n",
      "        [ 2.9549,  2.3109,  2.2647,  ..., -2.4141, -2.4368, -2.4930]])\n"
     ]
    }
   ],
   "source": [
    "print(sorted_loss_c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 516, 3462, 4723,  ..., 5513, 6714, 3574],\n",
      "        [7089, 8580, 7688,  ..., 2263, 1112, 6523],\n",
      "        [7573, 5141, 4916,  ..., 3301, 4945, 2366],\n",
      "        [4381, 4456, 7522,  ..., 7819, 2700, 1801],\n",
      "        [8290, 6671, 8146,  ..., 4215, 3745, 2722]])\n"
     ]
    }
   ],
   "source": [
    "print(mapping_loss_c3_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    1,    2,  ..., 8729, 8730, 8731],\n",
      "        [   0,    1,    2,  ..., 8729, 8730, 8731],\n",
      "        [   0,    1,    2,  ..., 8729, 8730, 8731],\n",
      "        [   0,    1,    2,  ..., 8729, 8730, 8731],\n",
      "        [   0,    1,    2,  ..., 8729, 8730, 8731]])\n",
      "tensor([[8211, 8237, 8238,  ..., 8536, 8537, 8538],\n",
      "        [ 205,  206,  207,  ...,  764,  772,  805],\n",
      "        [1243,  206,  207,  ...,   79,  393,  433],\n",
      "        [7494, 7533, 7551,  ..., 8525, 8526, 8527],\n",
      "        [7888, 7937, 7945,  ..., 8520, 8521, 8522]])\n"
     ]
    }
   ],
   "source": [
    "sorted_mapping, loss_rank = mapping_loss_c3_index.sort(dim=1)\n",
    "print(sorted_mapping)\n",
    "print(loss_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_c3[0, loss_rank[0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_c3[0, loss_rank[0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py39DeepLeaerning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "09729332f671cc9efac8a6faf8ef7d4a023ceb58c2a37747e371e1ffe225dc86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
