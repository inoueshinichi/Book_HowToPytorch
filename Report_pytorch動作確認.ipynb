{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### listの動作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "layers = [1,2,3]\n",
    "layers += [5,6,7]\n",
    "print(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.Tensorの次元の増減"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "weight = nn.Parameter(torch.Tensor(512))\n",
    "init.constant_(weight, 20)\n",
    "print(weight.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.unsqueeze(0).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.unsqueeze(0).unsqueeze(2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.unsqueeze(0).unsqueeze(2).unsqueeze(3).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 512, 38, 38])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 5\n",
    "x = torch.ones((batch_size, 512, 38, 38))\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 対象の変数の次元を別の変数の次元と同じにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 512, 38, 38])\n"
     ]
    }
   ],
   "source": [
    "ww = weight.unsqueeze(0).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
    "print(ww.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 512, 38, 38])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.pow(2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 38, 38])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.pow(2).sum(dim=1).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 次元を保ったままの和算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 38, 38])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.pow(2).sum(dim=1, keepdim=True).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 38, 38])\n",
      "tensor([[[22.6274, 22.6274, 22.6274,  ..., 22.6274, 22.6274, 22.6274],\n",
      "         [22.6274, 22.6274, 22.6274,  ..., 22.6274, 22.6274, 22.6274],\n",
      "         [22.6274, 22.6274, 22.6274,  ..., 22.6274, 22.6274, 22.6274],\n",
      "         ...,\n",
      "         [22.6274, 22.6274, 22.6274,  ..., 22.6274, 22.6274, 22.6274],\n",
      "         [22.6274, 22.6274, 22.6274,  ..., 22.6274, 22.6274, 22.6274],\n",
      "         [22.6274, 22.6274, 22.6274,  ..., 22.6274, 22.6274, 22.6274]]])\n"
     ]
    }
   ],
   "source": [
    "xx = x.pow(2).sum(dim=1, keepdim=True).sqrt()+1e-10\n",
    "print(xx.size())\n",
    "print(xx[0, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 512, 38, 38])\n",
      "tensor([[[[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]]],\n",
      "\n",
      "\n",
      "        [[[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]]],\n",
      "\n",
      "\n",
      "        [[[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]]],\n",
      "\n",
      "\n",
      "        [[[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]]],\n",
      "\n",
      "\n",
      "        [[[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]],\n",
      "\n",
      "         [[452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          ...,\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483],\n",
      "          [452.5483, 452.5483, 452.5483,  ..., 452.5483, 452.5483, 452.5483]]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "wx = xx * ww\n",
    "print(wx.size())\n",
    "print(wx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### list or np.ndarray からtorch.tensorを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., -1.],\n",
       "        [ 1., -1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1.0, -1.0], [1.0, -1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "torch.tensor(np.array([[1,2,3],[4,5,6]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.tensor()はいつもデータをコピーする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ・タイプを指定してtensorを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0],\n",
       "        [0, 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros([2,4], dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.tensorのスライシング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(x[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 8, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "x[0][1] = 8\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.tensorからpython定義の数値を抽出する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1]])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1]])\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5000)\n",
      "2.5\n",
      "torch.strided\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(2.5)\n",
    "print(x)\n",
    "print(x.item())\n",
    "print(x.layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.tensorは自動微分OFFの状態で生成される"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requires_grad:  False\n",
      "torch.strided\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1., -1.], [1., 1.]])\n",
    "print(\"requires_grad: \", x.requires_grad)\n",
    "print(x.layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requires_grad:  True\n",
      "x.grad:  None\n",
      "out:  tensor(4., grad_fn=<SumBackward0>)\n",
      "x.grad after out.backward(): \n",
      " tensor([[ 2., -2.],\n",
      "        [ 2.,  2.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1., -1.], [1., 1.]], requires_grad=True)\n",
    "print(\"requires_grad: \", x.requires_grad)\n",
    "print(\"x.grad: \", x.grad)\n",
    "out = x.pow(2).sum()\n",
    "print(\"out: \", out)\n",
    "out.backward()\n",
    "print(\"x.grad after out.backward(): \\n\", x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在の実装では, torch.tensorはメモリのオーバヘッドが大きいので、小さな複数のtorch.tensorを運用するのはメモリ消費が激しくなる."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dtypeとdeviceを引き継きながら、既存データからデータをコピーしたtorch.tensorを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1],\n",
      "        [2, 3]], dtype=torch.int8)\n",
      "tensor([1, 1], dtype=torch.int8)\n",
      "tensor([1, 1], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones((2,), dtype=torch.int8)\n",
    "data = [[0,1],[2,3]]\n",
    "print(tensor.new_tensor(data))\n",
    "print(tensor.clone())\n",
    "print(tensor.clone().detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### requires_gradを変更する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[0,1],[2,3]], dtype=torch.float32)\n",
    "print(x.requires_grad)\n",
    "x.requires_grad_(True) # 浮動小数点型のみ勾配変数を持つ\n",
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new_full(size,fill_value,dtype=None,device=None,requires_grad=False) -> Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.1416, 3.1416, 3.1416, 3.1416],\n",
       "        [3.1416, 3.1416, 3.1416, 3.1416],\n",
       "        [3.1416, 3.1416, 3.1416, 3.1416]], dtype=torch.float64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dtypeとdeviceを継承\n",
    "tensor = torch.ones((2,), dtype=torch.float64)\n",
    "tensor.new_full((3,4), fill_value=3.141592)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new_empty(size,dtype=None,device=None,requires_grad=False) -> Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1210e-44, 0.0000e+00, 7.0373e-25],\n",
      "        [1.4013e-45, 0.0000e+00, 0.0000e+00]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(())\n",
    "tensor = tensor.new_empty((2,3))\n",
    "print(tensor)\n",
    "print(tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new_ones(size,dtype=None,device=None,requires_grad=False) -> Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1],\n",
       "        [1, 1, 1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor((), dtype=torch.int32)\n",
    "tensor.new_ones((2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new_zero(size,dtype=None,device=None,requires_grad=False) -> Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor((), dtype=torch.float64)\n",
    "tensor.new_zeros((2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.tensorがGPUメモリにあるか否かのチェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor((), dtype=torch.float32)\n",
    "print(tensor)\n",
    "print(tensor.is_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quantizedか否かのチェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(tensor.is_quantized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorのdeviceチェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(tensor.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 次元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.dim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 転置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1],\n",
      "        [2, 3]], dtype=torch.int32)\n",
      "tensor([[0, 2],\n",
      "        [1, 3]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[0,1],[2,3]], dtype=torch.int32)\n",
    "print(x)\n",
    "print(x.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 要素数を維持しながらtensorの形状を変える。もし引数に与えた要素数が元の数値より低い場合は、元のtensorの中身は削られる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a shape torch.Size([3, 3])\n",
      "x shape torch.Size([9])\n",
      "resized a shape tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
      "c tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
      "False\n",
      "b shape torch.Size([2, 2])\n",
      "resized a shape tensor([[0, 1],\n",
      "        [2, 3]])\n",
      "a shape torch.Size([2, 2])\n",
      "y tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "set_sizes_contiguous is not allowed on a Tensor created from .data or .detach().\nIf your intent is to change the metadata of a Tensor (such as sizes / strides / storage / storage_offset)\nwithout autograd tracking the change, remove the .data / .detach() call and wrap the change in a `with torch.no_grad():` block.\nFor example, change:\n    x.data.set_(y)\nto:\n    with torch.no_grad():\n        x.set_(y)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-66aeb80cc133>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resized y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_as_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: set_sizes_contiguous is not allowed on a Tensor created from .data or .detach().\nIf your intent is to change the metadata of a Tensor (such as sizes / strides / storage / storage_offset)\nwithout autograd tracking the change, remove the .data / .detach() call and wrap the change in a `with torch.no_grad():` block.\nFor example, change:\n    x.data.set_(y)\nto:\n    with torch.no_grad():\n        x.set_(y)"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[0,1,2],[3,4,5],[6,7,8]])\n",
    "y = a.clone().detach()\n",
    "x = torch.tensor([0,1,2,3,4,5,6,7,8])\n",
    "print(\"a shape\", a.size())\n",
    "print(\"x shape\", x.size())\n",
    "print(\"resized a shape\", a.resize_as_(x))\n",
    "\n",
    "c = a.clone().detach() # 元tensor:aの自動微分の関係を引き継がないためにdetach()が必要。\n",
    "print(\"c\", c)\n",
    "print(c is a)\n",
    "\n",
    "b = torch.tensor([[9,8],[6,5]])\n",
    "print(\"b shape\", b.size())\n",
    "print(\"resized a shape\", a.resize_as_(b))\n",
    "print(\"a shape\", a.size())\n",
    "\n",
    "e = torch.tensor([[0,0],[0,0]])\n",
    "print(\"y\", y)\n",
    "print(\"resized y\", y.resize_as_(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 8732])\n",
      "tensor([[ 2, 17,  4,  ..., 12,  3, 13],\n",
      "        [ 1, 13, 15,  ...,  7, 20, 12],\n",
      "        [15, 13, 20,  ...,  6, 15, 18],\n",
      "        [ 9,  9,  7,  ...,  8, 16, 14],\n",
      "        [ 0,  3,  4,  ...,  0,  8,  4]])\n"
     ]
    }
   ],
   "source": [
    "num_batch = 5\n",
    "conf_t_label = torch.randint(0, 21,(num_batch, 8732))\n",
    "print(conf_t_label.size())\n",
    "print(conf_t_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True,  True,  True,  ...,  True,  True,  True],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True],\n",
      "        [False,  True,  True,  ..., False,  True,  True]])\n"
     ]
    }
   ],
   "source": [
    "pos_mask = conf_t_label > 0\n",
    "print(pos_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8303],\n",
      "        [8337],\n",
      "        [8304],\n",
      "        [8314],\n",
      "        [8327]])\n"
     ]
    }
   ],
   "source": [
    "num_pos = pos_mask.long().sum(dim=1, keepdim=True)\n",
    "print(num_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([43660])\n",
      "tensor([-0.6359, -0.8697,  0.5686,  ..., -1.2054, -1.1376,  1.0267])\n"
     ]
    }
   ],
   "source": [
    "loss_c = torch.randn((num_batch * 8732,))\n",
    "print(loss_c.size())\n",
    "print(loss_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 8732])\n",
      "tensor([[-0.6359, -0.8697,  0.5686,  ...,  0.8119, -3.1378, -1.0195],\n",
      "        [ 1.3421,  1.1616,  1.1381,  ..., -0.5337,  0.2220, -1.9861],\n",
      "        [-0.1525,  0.7679,  1.5779,  ..., -1.2768,  0.5376,  0.7597],\n",
      "        [ 1.6534, -0.3884, -0.3403,  ...,  1.2776, -1.5996,  0.0105],\n",
      "        [ 0.5576, -1.5604, -0.5169,  ..., -1.2054, -1.1376,  1.0267]])\n"
     ]
    }
   ],
   "source": [
    "loss_c2 = loss_c.view(num_batch, -1)\n",
    "print(loss_c2.size())\n",
    "print(loss_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6359, -0.8697,  0.5686,  ...,  0.3195, -1.1376,  1.0267])\n",
      "torch.Size([41585])\n"
     ]
    }
   ],
   "source": [
    "print(loss_c2[pos_mask])\n",
    "print(loss_c2[pos_mask].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 8732])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.5576,  0.0000,  0.0000,  ..., -1.2054,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "loss_c3 = loss_c2.clone()\n",
    "loss_c3[pos_mask] = 0\n",
    "print(loss_c3.size())\n",
    "print(loss_c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_loss_c3, mapping_loss_c3_index = loss_c3.sort(dim=1, descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.7124,  2.5287,  2.3202,  ..., -2.9559, -3.1229, -3.2518],\n",
      "        [ 2.7407,  2.6826,  2.5023,  ..., -2.3404, -2.6146, -2.7753],\n",
      "        [ 3.4014,  2.6461,  2.5337,  ..., -2.6235, -2.6949, -3.1518],\n",
      "        [ 2.5460,  2.4067,  2.2981,  ..., -2.5410, -2.8131, -3.5553],\n",
      "        [ 2.6428,  2.5604,  2.5286,  ..., -1.9720, -1.9876, -2.0845]])\n"
     ]
    }
   ],
   "source": [
    "print(sorted_loss_c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4211, 2647, 5002,  ..., 5506,  968,   91],\n",
      "        [8639, 4187, 4762,  ..., 6760, 2741, 7575],\n",
      "        [3664, 5108, 6315,  ..., 2786, 2742, 1756],\n",
      "        [2957,  601,   62,  ..., 7450, 7385, 5642],\n",
      "        [4187, 8213, 7061,  ..., 2539, 1140, 2984]])\n"
     ]
    }
   ],
   "source": [
    "print(mapping_loss_c3_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    1,    2,  ..., 8729, 8730, 8731],\n",
      "        [   0,    1,    2,  ..., 8729, 8730, 8731],\n",
      "        [   0,    1,    2,  ..., 8729, 8730, 8731],\n",
      "        [   0,    1,    2,  ..., 8729, 8730, 8731],\n",
      "        [   0,    1,    2,  ..., 8729, 8730, 8731]])\n",
      "tensor([[4368, 7212, 5788,  ..., 2952, 2953, 7962],\n",
      "        [4368, 7213, 5789,  ..., 2947, 2948, 8295],\n",
      "        [4367, 7194, 5778,  ..., 2947, 2948, 7541],\n",
      "        [4370, 7210, 5789,  ..., 2949, 2950, 7566],\n",
      "        [ 112, 4365, 5782,  ..., 8686, 2947, 7293]])\n"
     ]
    }
   ],
   "source": [
    "sorted_mapping, loss_rank = mapping_loss_c3_index.sort(dim=1)\n",
    "print(sorted_mapping)\n",
    "print(loss_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_c3[0, loss_rank[0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_c3[0, loss_rank[0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('QtPy36': conda)",
   "language": "python",
   "name": "python36964bitqtpy36condac09d93b7e2bc4050ab06fc2ff7a46e56"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
