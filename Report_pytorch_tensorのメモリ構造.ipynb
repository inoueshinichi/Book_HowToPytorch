{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### メモリ上の実体はStorageオブジェクトが持つ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorのデータはメモリ上では全て1次元配列として保存されており、その実体を管理しているのがStorageオブジェクト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a  tensor([[[1.0000, 2.0000, 3.0000],\n",
      "         [4.0000, 5.0000, 6.0000]],\n",
      "\n",
      "        [[0.1000, 0.2000, 0.3000],\n",
      "         [0.4000, 0.5000, 0.6000]]])\n",
      "a size torch.Size([2, 2, 3])\n",
      "<class 'torch.storage.TypedStorage'>\n",
      " 1.0\n",
      " 2.0\n",
      " 3.0\n",
      " 4.0\n",
      " 5.0\n",
      " 6.0\n",
      " 0.10000000149011612\n",
      " 0.20000000298023224\n",
      " 0.30000001192092896\n",
      " 0.4000000059604645\n",
      " 0.5\n",
      " 0.6000000238418579\n",
      "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 12]\n"
     ]
    }
   ],
   "source": [
    "a = torch.FloatTensor([[[1,2,3],[4,5,6]],[[0.1,0.2,0.3],[0.4,0.5,0.6]]])\n",
    "print(\"a \", a)\n",
    "print(\"a size\", a.size())\n",
    "a_storage = a.storage()\n",
    "print(type(a_storage))\n",
    "print(a_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.0\n",
      " 2.0\n",
      " 3.0\n",
      " 4.0\n",
      " 10.0\n",
      " 6.0\n",
      " 0.10000000149011612\n",
      " 0.20000000298023224\n",
      " 0.30000001192092896\n",
      " 0.4000000059604645\n",
      " 0.5\n",
      " 0.6000000238418579\n",
      "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 12]\n"
     ]
    }
   ],
   "source": [
    "a[0,1,1] = 10\n",
    "print(a_storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorはStorageに対するビューの役目を果たす。\n",
    "TensorからStorage(1次元配列)へマッピングするために、Tensorではオフセットとストライドを持っている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_offset 0\n",
      "a_stride (6, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "a_offset = a.storage_offset()\n",
    "print(\"a_offset\", a_offset)\n",
    "a_stride = a.stride()\n",
    "print(\"a_stride\", a_stride)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aの場合、オフセット：0, ストライド:(6,3,1)\n",
    "Storageのindex = 0(offset) + 0次index * 6 + 1次index * 3 + 2次index * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorにインデックスを使ってアクセスすると、Storageは同じでオフセット・ストライドのみが異なるTensorオブジェクトが生成される。つまり、メモリコピーは発生しない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a tensor([[[ 1.0000,  2.0000,  3.0000],\n",
      "         [ 4.0000, 10.0000,  6.0000]],\n",
      "\n",
      "        [[ 0.1000,  0.2000,  0.3000],\n",
      "         [ 0.4000,  0.5000,  0.6000]]])\n",
      "a size torch.Size([2, 2, 3])\n",
      "0 (6, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"a\", a)\n",
    "print(\"a size\", a.size())\n",
    "print(a.storage_offset(), a.stride())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b tensor([[[0.1000, 0.2000, 0.3000],\n",
      "         [0.4000, 0.5000, 0.6000]]])\n",
      "b size torch.Size([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "b = a[1:]\n",
    "print(\"b\", b)\n",
    "print(\"b size\", b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 (6, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "print(b.storage_offset(), b.stride())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c tensor([[0.1000, 0.4000],\n",
      "        [0.2000, 0.5000],\n",
      "        [0.3000, 0.6000]])\n",
      "c size torch.Size([3, 2])\n",
      " 1.0\n",
      " 2.0\n",
      " 3.0\n",
      " 4.0\n",
      " 10.0\n",
      " 6.0\n",
      " 0.10000000149011612\n",
      " 0.20000000298023224\n",
      " 0.30000001192092896\n",
      " 0.4000000059604645\n",
      " 0.5\n",
      " 0.6000000238418579\n",
      "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 12]\n"
     ]
    }
   ],
   "source": [
    "c = b.squeeze(0).transpose(0, 1)\n",
    "print(\"c\", c)\n",
    "print(\"c size\", c.size())\n",
    "print(c.storage())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.],\n",
      "         [ 3.,  4.,  5.],\n",
      "         [ 6.,  7.,  8.]],\n",
      "\n",
      "        [[10., 11., 12.],\n",
      "         [13., 14., 15.],\n",
      "         [16., 17., 18.]]])\n",
      "torch.Size([2, 3, 3])\n",
      " 0.0\n",
      " 1.0\n",
      " 2.0\n",
      " 3.0\n",
      " 4.0\n",
      " 5.0\n",
      " 6.0\n",
      " 7.0\n",
      " 8.0\n",
      " 10.0\n",
      " 11.0\n",
      " 12.0\n",
      " 13.0\n",
      " 14.0\n",
      " 15.0\n",
      " 16.0\n",
      " 17.0\n",
      " 18.0\n",
      "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 18]\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[[0,1,2],[3,4,5],[6,7,8]],[[10,11,12],[13,14,15],[16,17,18]]])\n",
    "print(x)\n",
    "print(x.size())\n",
    "print(x.storage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.],\n",
      "         [10., 11., 12.]],\n",
      "\n",
      "        [[ 3.,  4.,  5.],\n",
      "         [13., 14., 15.]],\n",
      "\n",
      "        [[ 6.,  7.,  8.],\n",
      "         [16., 17., 18.]]])\n",
      "torch.Size([3, 2, 3])\n",
      " 0.0\n",
      " 1.0\n",
      " 2.0\n",
      " 3.0\n",
      " 4.0\n",
      " 5.0\n",
      " 6.0\n",
      " 7.0\n",
      " 8.0\n",
      " 10.0\n",
      " 11.0\n",
      " 12.0\n",
      " 13.0\n",
      " 14.0\n",
      " 15.0\n",
      " 16.0\n",
      " 17.0\n",
      " 18.0\n",
      "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 18]\n"
     ]
    }
   ],
   "source": [
    "y = x.transpose(0, 1)\n",
    "print(y)\n",
    "print(y.size())\n",
    "print(y.storage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  3.,  6.],\n",
      "         [ 1.,  4.,  7.],\n",
      "         [ 2.,  5.,  8.]],\n",
      "\n",
      "        [[10., 13., 16.],\n",
      "         [11., 14., 17.],\n",
      "         [12., 15., 18.]]])\n",
      "torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "w = x.transpose(1,2)\n",
    "print(w)\n",
    "print(w.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0., 10.],\n",
      "         [ 3., 13.],\n",
      "         [ 6., 16.]],\n",
      "\n",
      "        [[ 1., 11.],\n",
      "         [ 4., 14.],\n",
      "         [ 7., 17.]],\n",
      "\n",
      "        [[ 2., 12.],\n",
      "         [ 5., 15.],\n",
      "         [ 8., 18.]]])\n",
      "torch.Size([3, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "u = x.transpose(0,2)\n",
    "print(u)\n",
    "print(u.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### contiguous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "offsetとstrideによってTensorからStorageへマッピングされるので、メモリレイアウトは変更されない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorからStorageへのマッピングがメモリの連続した領域へのアクセスなっているかどうかをチェックする→is_contiguous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "連続している方が、CPU/GPUのキャッシュを効率的に使えるため、場合によっては、今チェックが必要になる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.0\n",
      " 2.0\n",
      " 3.0\n",
      " 4.0\n",
      " 5.0\n",
      " 6.0\n",
      "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]\n",
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4., 10.,  6.]])\n",
      " 1.0\n",
      " 2.0\n",
      " 3.0\n",
      " 4.0\n",
      " 10.0\n",
      " 6.0\n",
      "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1,2,3],[4,5,6]], dtype=torch.float32)\n",
    "a_storage = a.storage()\n",
    "print(a_storage)\n",
    "\n",
    "a[1,1] = 10\n",
    "print(a)\n",
    "\n",
    "print(a_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4., 10.,  6.]])\n",
      "3 (3, 1)\n",
      "tensor([[ 1.,  4.],\n",
      "        [ 2., 10.],\n",
      "        [ 3.,  6.]])\n",
      "0 (1, 3)\n"
     ]
    }
   ],
   "source": [
    "b = a[1:]\n",
    "print(b)\n",
    "print(b.storage_offset(), b.stride())\n",
    "\n",
    "c = a.transpose(0, 1)\n",
    "print(c)\n",
    "print(c.storage_offset(), c.stride())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4., 10., 11.]])\n"
     ]
    }
   ],
   "source": [
    "a[1,2] = 11\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4., 10., 11.]])\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cはtransposeでメモリ配列を不連続に参照している"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True False\n"
     ]
    }
   ],
   "source": [
    "print(a.is_contiguous(), b.is_contiguous(), c.is_contiguous())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0\n",
       " 2.0\n",
       " 3.0\n",
       " 4.0\n",
       " 10.0\n",
       " 11.0\n",
       "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0\n",
       " 2.0\n",
       " 3.0\n",
       " 4.0\n",
       " 10.0\n",
       " 11.0\n",
       "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a tensor([[ 1.,  2.,  3.],\n",
      "        [ 4., 10., 11.]])\n",
      "c tensor([[ 1.,  4.],\n",
      "        [ 2., 10.],\n",
      "        [ 3., 11.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"a\", a)\n",
    "print(\"c\", c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aの参照順序: 0->1->2->3->4->5 連続\n",
    "cの参照順序: 0->3->1->4->2->5 不連続"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cを参照順序でメモリレイアウトを連続にする→contigous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_strage:  1.0\n",
      " 2.0\n",
      " 3.0\n",
      " 4.0\n",
      " 10.0\n",
      " 11.0\n",
      "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]\n",
      "c_is_contiguous :  False\n",
      "c_cont_strage:  1.0\n",
      " 4.0\n",
      " 2.0\n",
      " 10.0\n",
      " 3.0\n",
      " 11.0\n",
      "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]\n",
      "c_cont_is_contiguous :  True\n"
     ]
    }
   ],
   "source": [
    "print(\"c_strage:\", c.storage())\n",
    "print(\"c_is_contiguous : \", c.is_contiguous())\n",
    "c_cont = c.contiguous()\n",
    "print(\"c_cont_strage:\", c_cont.storage())\n",
    "print(\"c_cont_is_contiguous : \", c_cont.is_contiguous())\n",
    "# メモリコピーが発生する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### contigous()以外でメモリコピーが発生する事象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "明示的にメモリコピーを行う(=Storageを生成する)→ clone()メソッド"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4., 10., 11.]])\n",
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4., 10., 11.]])\n",
      "tensor([[100.,   2.,   3.],\n",
      "        [  4.,  10.,  11.]])\n",
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4., 10., 11.]])\n"
     ]
    }
   ],
   "source": [
    "a_clone = a.clone()\n",
    "print(a)\n",
    "print(a_clone)\n",
    "a_clone[0,0] = 100\n",
    "print(a_clone)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "booleanインデックスを使用する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10., 11.])\n",
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4., 10., 11.]])\n"
     ]
    }
   ],
   "source": [
    "a_filterd = a[a >= 10]\n",
    "print(a_filterd)\n",
    "\n",
    "a_filterd[0] = 100\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "値そのものの変更やもとのStorageサイズを変更するようなメソッドでもコピーが発生"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.transposeやviewはoffsetとstrideの変更で済むため、コピーは発生しない\n",
    "2.末尾\"_\"のTensorメソッドはStorage内のメモリを上書きする(in-place)のため、コピーは発生しない "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1\n",
      " 4\n",
      " 9\n",
      "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 3]\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3])\n",
    "b = torch.tensor([4,5,6])\n",
    "\n",
    "# コピー発生\n",
    "c = torch.pow(a, 2)\n",
    "print(c.storage())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1\n",
      " 16\n",
      " 81\n",
      "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 3]\n",
      " 1\n",
      " 16\n",
      " 81\n",
      "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 3]\n"
     ]
    }
   ],
   "source": [
    "# コピー発生しない\n",
    "c_ = c.pow_(2)\n",
    "print(c_.storage())\n",
    "\n",
    "print(c.storage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 5\n",
      " 6\n",
      "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 6]\n"
     ]
    }
   ],
   "source": [
    "# コピー発生\n",
    "d = torch.cat((a,b))\n",
    "print(d.storage())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPUにデータを送るとメモリコピーになる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], device='cuda:0')\n",
      " 1.0\n",
      " 2.0\n",
      " 3.0\n",
      " 4.0\n",
      " 5.0\n",
      " 6.0\n",
      "[torch.storage.TypedStorage(dtype=torch.float32, device=cuda:0) of size 6]\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)\n",
    "\n",
    "a_gpu = a.to(device=\"cuda\")\n",
    "\n",
    "print(a_gpu)\n",
    "# tensor([[1., 2., 3.],\n",
    "#         [4., 5., 6.]], device='cuda:0')\n",
    "\n",
    "print(a_gpu.storage())\n",
    "#  1.0\n",
    "#  2.0\n",
    "#  3.0\n",
    "#  4.0\n",
    "#  5.0\n",
    "#  6.0\n",
    "# [torch.cuda.FloatStorage of size 6]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py39DeepLeaerning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "09729332f671cc9efac8a6faf8ef7d4a023ceb58c2a37747e371e1ffe225dc86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
